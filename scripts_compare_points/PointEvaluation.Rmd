---
title: "Point evaluation of DSM products using WoSIS"
author: "D G Rossiter"
date: "`r format(Sys.Date(), '%d-%B-%Y')`"
params:
   lrc_long: -76
   lrc_lat: 42
   size: 1 
   voi.n: 4
   depth.n: 1
output:
  word_document:
    toc: yes
  html_document:
    fig_height: 4
    fig_width: 6
    number_section: yes
    theme: spacelab
    toc: yes
    toc_float: yes
bibliography: wosis.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warnings = FALSE, purl = FALSE)
```

# Introduction

Here we evaluate the traditional measures of DSM accuracy using known points.
We get the points from the WoSIS "Latest" data.
This dataset contains the most recent version of standardised soil data served from WoSIS. 

For an overview of WoSIS, see https://www.isric.org/explore/wosis. This links to https://www.isric.org/explore/wosis/accessing-wosis-derived-datasets which explains the difference between snapshot and dynamic datasets, and how to access them.

The [Procedures Manual](http://dx.doi.org/10.17027/isric-wdc-2020-01) describes how the WoSIS database is built.

## Packages

```{r load.package}
library(rgdal)          # GDAL access from R
library(gdalUtils)      # wrappers for GDAL utility programs that could be
                        #  called from the command line
library(sp)             # spatial data types, ASDAR structures
library(sf)             # spatial data types -- Simple Features
library(ggplot2)        # gpplot graphics
library(dplyr)
```

Check for a valid GDAL installation. If you have installed a binary version of `rgdal`, GDAL should be valid.

```{r set.gdal, eval=FALSE, purl=FALSE}
gdal_setInstallation(rescan=TRUE, verbose=TRUE)
valid_install <- !is.null(getOption("gdalUtils_gdalPath"))
if (valid_install)
   print("Valid GDAL found") else { stop("No valid GDAL") }
```

If you do not have a valid GDAL installation, see https://gdal.org and the package DESCRIPTION for `rgdal`. 

## WoSIS Web Feature Service

The "latest" (dynamic) version of WoSIS is provided via
[WFS (Web Feature Services)](http://www.opengeospatial.org/standards/wfs).
This is described in less technical terms in [Wikipedia](https://en.wikipedia.org/wiki/Web_Feature_Service).

WFS allows you to incorporate geographic data into your own GIS projects, unlike WMS (Web Map Service), which only displays geographic data within a GIS. Here we use R as the GIS, since it can handle both geographic and feature-space information.

Specify the web address of the "latest" version of WoSIS:

```{r specify.wfs.address}
wfs <- "WFS:http://maps.isric.org/mapserv?map=/map/wosis_latest.map"
```

# Setup

## Property to use for accuracy assessment

```{r}
voi.list.wosis <- c("clay", "silt", "sand", "phaq", "cecph7", 
                    "orgc", "bdfi33", "cfvo")
voi.list.gnatsgo <- c("claytotal_r", "silttotal_r", "sandtotal_r",
                  "ph1to1h2o_r", "cec7_r", "om_r",   # note SOM not SOC
                  "dbthirdbar_r", "sieveno10_r") # passing 2.0 mm sieve, complement is coarse fragments
voi.list.sg <- c("clay", "silt", "sand", "phh2o", "cec", "soc", "bdod", "cfvo")
voi.list.gsm <- c("claytotal_r_g_kg", "silttotal_r_g_kg", "sandtotal_r_g_kg", 
                  "ph1to1h2o_r_ions_pHx10", "ecec_r_cmolc_kg", "soc_r_mr_g_gF",
                  "dbthirdbar_lt2mm_r_g_cm3", "gravel_r_vol_ratio_m3_m3")
voi.list.issr8 <- c("clay", "silt","sand","ph", "cec", "", "", "")
voi.list.polaris <- c("clay", "silt", "sand", "ph", "", "om", "bd", "") 
voi.list.psu <- c("clay", "", "sand", "ph_h2o", "", "soc", "bd", "")
voi.list.landgis <- c("clay.wfraction_usda.3a1a1a",
                      "silt.wfraction_usda.3a1a1a",
                      "sand.wfraction_usda.3a1a1a",
                      "ph.h2o_usda.4c1a2a",
                      "",
                      "organic.carbon_usda.6a1c",
                      "bulkdens.fineearth_usda.4a1h",
                      "coarsefrag.vfraction_usda_3b1")
```

Select the position in these lists

```{r}
voi.n <- params$voi.n   # variable of interest, SoilGrids name
voi.wosis <- voi.list.wosis[voi.n]
voi.gnatsgo <- voi.list.gnatsgo[voi.n]
voi.sg <- voi.list.sg[voi.n]
voi.issr8 <- voi.list.issr8[voi.n]
voi.polaris <- voi.list.polaris[voi.n]
voi.psu <- voi.list.psu[voi.n]
voi.gsm <- voi.list.gsm[voi.n]
```

## Area of Interest (AOI) {#aoi}

Specify the _lower-right corner_ and _tile size_ from the YAML or rendering parameters:

```{r lrc}
tile.lrc <- c(params$lrc_long, params$lrc_lat) # lower-right corner
tile.size <- params$size                # tile dimensions
```

Compute the upper-right corner $1^\circ$ west and north:

```{r ulc}
tile.ulc <- c(tile.lrc[1]-tile.size, tile.lrc[2]+tile.size) # upper-left corner
```


## Depth of interest {#depth}

Depth slices:

```{r}
depth.list.sg <- c("0-5", "5-15", "15-30", "30-60", "60-100", "100-200")
depth.list.gnatsgo <- c("05", "515", "1530", "3060", "60100", "100200")
# SPCGUSA100 predicts at points, these were averaged to GSM slices during import
# --- these have the SG names
# LandGIS predicts at points, these were averaged to GSM slices during import
# --- these have the SG names
depth.list.polaris <- gsub("-", "_", depth.list.sg)
depth.list.issr8 <- gsub("-", "", depth.list.sg)
depth.list.gsm <- c("000_005", "005_015", "015_030", "030_060", "060_100", "100_200")
```

Select the depth slice:

```{r}
depth <- params$depth.n
tmp <- as.numeric(strsplit(depth.list.sg[depth], "-")[[1]])
depth.ul <- tmp[1]; depth.ll <- tmp[2]
```


# Profiles in the target region

The layer `"ms:wosis_latest:wosis_latest_profiles"` contains the site information. 

The `rgdal::ogrinfo` function displays information about a dataset accessible via GDAL. Here we see the metadata for the site information. Note the `so` "summary only" option. This supresses listing of features, and shows only the summary information. We choose this because there are many profiles in the entire dataset.

The `rgdal::ogrinfo` function also allows an optional limitation to a bounding box with the `spat` argument, as a four-element vector `(xmin, ymin, xmax, ymax)`. These are the coördinates in the layer's Coordinate Reference System (CRS), in this case geographic coördinates.

For example, all the profile (site) information from a $1^\circ \times 1^\circ$ tile:

Note: the `q=FALSE` option lists the geometry and feature count.

```{r ogrinfo.eu.profiles.1}
system.time(
  degree.profiles.info <-
    ogrinfo(wfs, ro=TRUE, so=TRUE, q=FALSE,
            layer="ms:wosis_latest_profiles",
          # c(xmin,ymin,xmax,ymax) 
            spat=c(tile.ulc[1], tile.lrc[2], tile.lrc[1], tile.ulc[2]))
)
head(degree.profiles.info, 8)
degree.profiles.info[41:60]
```

Show the number of features, the spatial extent, and the Coordinate Reference System (CRS):

```{r ogrinfo.eu.profiles.2}
ix.f <- grep("Feature Count", degree.profiles.info)
degree.profiles.info[ix.f]
ix.e <- grep("Extent", degree.profiles.info)
degree.profiles.info[ix.e]
ix.g <- grep("GEOGCRS", degree.profiles.info)
cat(paste(degree.profiles.info[ix.g:(ix.g+17)], collapse="\n"))
```

Here we see the number of profiles in this tile, the extent (a bit smaller than the bounding box we requested), and  the CRS formatted as ["Well-Known Text"](http://docs.opengeospatial.org/is/12-063r5/12-063r5.html).
The CRS corresponds to [EPSG code](https://www.epsg.org) `4326`, i.e., geographic coördinates on the WGS84 datum. 

The data field names and their data types are listed in the [Procedures Manual](http://dx.doi.org/10.17027/isric-wdc-2020-01).


## Import WoSIS profiles to the client system

There seems to be no way to directly import from the WFS to an R workspace object, so there must first be an intermediate step: download the WFS layer in an appropriate format to a local directory, and then import as usual for GIS layers.

The `rgdal::ogr2ogr` function reads from one format on the server and writes to another in our client. The default output file format is an [ESRI Shapefile](https://en.wikipedia.org/wiki/Shapefile); other formats can be specified with the (optional) `f` argument.

The possible formats are listed [here](https://docs.geoserver.org/latest/en/user/services/wfs/outputformats.html). In this example we will use a CSV file as the intermediate step.

The `spat` argument can also be used here.

We set up a directory on the local file system to receive the downloaded files:

```{r setup.local.dir}
wosis.dir.name <- "./wosis_latest"
if (!file.exists(wosis.dir.name)) dir.create(wosis.dir.name)
```

Note that **import via `ogr2ogr` can be quite slow**, because it depends on the network and the remote server, which may have a speed limitation to avoid overloads. Many of these downloads may take 15-20 minutes clock time, while only requiring less than a minute of local computer time.


## WoSIS profiles as CSV files {#csv}

One output format for `ogr2ogr` is the CSV 'comma-separated values' plain-text file. These typically have one header row giving the name of each column (field), and then one row (case, tuple) per observation

For example, read the profile information for the tile defined above

```{r download.profiles.csv}
wosis.dir.name.tile <- "./wosis_latest/tile"
if (!file.exists(wosis.dir.name.tile)) dir.create(wosis.dir.name.tile)
src.layer.name <- "ms:wosis_latest_profiles"
dst.layer.name <- "wosis_latest_profiles_tile"
(dst.target.name <- paste0(wosis.dir.name.tile,"/",dst.layer.name,".csv"))
if (file.exists(dst.target.name)) { file.remove(dst.target.name) }
ogr2ogr(src=wfs, 
        dst=dst.target.name,
        layer=src.layer.name,
        f="CSV",
        # c(xmin,ymin,xmax,ymax) 
        spat=c(tile.ulc[1], tile.lrc[2], tile.lrc[1], tile.ulc[2]),
        overwrite=TRUE)
```

This file is about `r round(file.info(dst.target.name)$size/1024)` Kb.

## Read imported profiles into R

The `read.csv` function reads from a CSV file into an R `data.frame`.

Read the profiles (sites) from  the tile:

```{r import.profiles.csv}
layer.name <- "wosis_latest_profiles_tile"
system.time(
  profiles.tile <- read.csv(paste0(wosis.dir.name.tile, "/",layer.name,".csv"),
                stringsAsFactors = FALSE)
)
```

```{r}
dim(profiles.tile)
```


# WoSIS layers as CSV files 

Get the the property for the layers in these profiles. Note that this query can not be limited by coordinates, since they are not included in this table. So we get all the layers and then limit to the profiles of interest. This is a very large file, about 97Mb and may take several hours to download.

Note: if you want to make sure you have the latest version of the file, delete any existing file before running this.

```{r download.prop.csv}
src.layer.name <- paste0("wosis_latest_", voi.wosis)
dst.layer.name <- paste0("wosis_latest_", voi.wosis)
(dst.target.name <- paste0(wosis.dir.name,"/",dst.layer.name,".csv"))
if (!file.exists(dst.target.name)) { 
  ogr2ogr(src=wfs,
          dst=dst.target.name,
          layer=src.layer.name,
          f="CSV")
  file.info(dst.target.name)$size
}
```

## Read imported layers into R

The property per-layer. 

```{r import.prop.csv}
layer.name <- "wosis_latest_phaq"
system.time(
  prop.pts <- read.csv(file=paste0(wosis.dir.name,"/",layer.name,".csv"),
                stringsAsFactors = FALSE)
)
dim(prop.pts)
names(prop.pts)
```

## Limit to the region

```{r}
prop.tile <- prop.pts %>% 
  filter(profile_id %in% profiles.tile$profile_id)
dim(prop.tile)
```

## Extract the property over the depth slice




Each attribute has several names, with the following extensions:

* `value`  -- one or more values, in the format {1:value; 2:value...}, which are duplicate measurements 
* `value_avg`  -- the average of the values
* `method` -- text description of the analytical method
* `date` -- one or more values, in the format {1:yyyy-mm-dd; 2:yyyy-mm-dd...}, 
which are the dates each of th duplicate measurements was added to the database (not the original measurement date, nor the field sampling date)
* `dataset_id` -- text code of original database
* `profile_code` -- text code of profile from original database
* `licence` -- text string of the Creative Commons ^[https://creativecommons.org/licenses/] license for this value, e.g. `CC-BY-NC`

So for example the  attribute `bdfi33` has the following fields:

* `bdfi33_value`
* `bdfi33_value_avg`
* `bdfi33_method`
* `bdfi33_date`
* `bdfi33_dataset_id`
* `bdfi33_profile_code`
* `bdfi33_licence`

The format is `{seq:val[,seq:val]}` where the `seq` is an integer on `[1...]` indicating which measurement number -- note that there can be more than one measurement per property, e.g., repeated lab. measurements, and `val` is the numeric value.

But the average value has its own field, so if we only want the average, it is prepared for us. We see an example here, from six rows chosen to show several profiles with their layers:

```{r example.bd}
prop.tile[1:6, c("profile_id","upper_depth","lower_depth","phaq_value_avg")]
```

**To Do** indirection of the property names

## Add spatial reference

# Export for evaluation

Write an `Rdata` object with the coordinates and property value; this can then be compared with predictions of the various PSM methods.

```{r}
#
```

# Spatial objects     

Once the WoSIS profiles have been imported to R they can be converted to a spatial object in the `sp` package, by specifying the coördinates and the Coordinate Reference System (CRS). 
 
```{r coordinates.profiles}
coordinates(profiles.tile) <- c("longitude", "latitude")
proj4string(profiles.tile) <- CRS("+init=epsg:4326")
class(profiles.tile)
```

These can also be represented as Simple Features from the `sf` "Simple Features" package:

```{r coordinates.profiles.sf}
profiles.tile.sf <- st_as_sf(profiles.tile)
class(profiles.tile.sf)
```

Review some site information, e.g., the WRB Reference Soil Groups and the USDA classification

```{r profiles.wrb}
table(profiles.tile@data$cwrb_reference_soil_group)
table(profiles.tile.sf$cwrb_reference_soil_group)
table(profiles.tile@data$cstx_version)
table(profiles.tile@data$cstx_order_name)
table(profiles.tile@data$cstx_suborder)
table(profiles.tile@data$cstx_great_group)
table(profiles.tile@data$cstx_cstx_subgroup)
```

Note that most of these profiles do not have classifications.

And a map:

```{r map.profiles.wrb}
ggplot(data=profiles.tile.sf) +
  geom_sf()
```


# Working with WoSIS as a `SoilProfileCollection`

The `aqp` "Algorithms for Quantitive Pedology" package [@Beaudette_2013] defines data structures and functions specific to soil profile data, i.e., with site and linked layer information.

Load the package:

```{r load.aqp}
library(aqp)            # Algorithms for Quantitative Pedology
```


Convert the bulk density structure to a `SoilProfileCollection`, a data type defined in `aqp`. This data type has separate structures for the site (profile) and horizons.

Initialize with the horizons from the data frame created from the WoSIS layer. 
The `aqp::depth` function initializes the SoilProfileCollection object. The formula has the field name of the profile on the left, and the the field names of the horizon boundaries on the right. These fields are in the WoSIS layer.

```{r bd.aqp}
ds.aqp <- prop.tile
depths(ds.aqp) <- profile_id ~ upper_depth + lower_depth
is(ds.aqp)
slotNames(ds.aqp)
str(ds.aqp@site)
str(ds.aqp@horizons)
head(ds.aqp@site)
head(ds.aqp@horizons[c(2,5,6,7,10)], 12)
```

Note how the horizons have been grouped into sites, in the `@site` slot, and the per-horizon (by depth) values are in the `@horizons` slot. Here we have `r dim(ds.aqp@horizons)[1]` horizons in `r dim(ds.aqp@site)[1]` profiles.

Now this `SoilProfileCollection` can be used for many `aqp` functions. For example, here is the depth distribution of average bulk density of the components for the first 24 listed profiles, labelled by genetic horizon:

```{r plot.prop.spc,fig.width=12, fig.height=8}
plotSPC(ds.aqp[1:24,], name="layer_name", color='phaq_value_avg')
```

A few layers in this set of profiles are missing the soil property.

# References

